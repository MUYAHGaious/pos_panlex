
# ğŸ§  Multilingual POS-Aligned Dataset Builder (Colab Edition)

Easily build a **POS-aligned multilingual dataset** from English to **French (FRA)**, **Bambara (BAM)**, and **Wolof (WOL)** using:

âœ… **English WordNet** & **Treebank corpora**  
âœ… **POS tagging** (WordNet + Universal Dependencies)  
âœ… **Meta AIâ€™s NLLB-200 model** for efficient translation  

---

## ğŸ“š Supported POS Categories

We support two major POS systems:  

- **WordNet POS**: `NOUN`, `VERB`, `ADJ`, `ADV`  
- **Universal Dependencies (UD) POS**: `DET`, `PRON`, `ADP`, `CONJ`, `NUM`, `INTJ`  

ğŸ”¹ Each category can include up to **500 words** (customizable).  

---

## ğŸš€ How to Use

### ğŸ§© 1. Open the Notebook

Run the full notebook in **[Google Colab](https://colab.research.google.com/)** or upload it yourself.  

---

### ğŸ› ï¸ 2. Install Dependencies (Handled Automatically)

```python
!pip install transformers sentencepiece --quiet
```

---

### ğŸ“¥ 3. Extract English Words by POS

```python
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('treebank')
nltk.download('universal_tagset')

# Extract up to 500 words per POS category
```

ğŸ”¹ Uses:
- **WordNet** (`NOUN`, `VERB`, `ADJ`, `ADV`)
- **Treebank Corpus** (`DET`, `PRON`, etc.)

ğŸ“‚ **Output file**:  
```plaintext
english_words_by_pos.json
```

---

### ğŸŒ 4. Translate with NLLB-200

The notebook loads the **`facebook/nllb-200-distilled-600M`** model via HuggingFace to:

âœ” Translate words into **French (FRA), Bambara (BAM), and Wolof (WOL)**  
âœ” Handle batching and retries automatically  

```python
from transformers import pipeline
# Load NLLB model and perform translations
```

---

### ğŸ’¾ 5. Final Dataset Output  

ğŸ“‚ **Output file**:  
```plaintext
multilingual_translations.csv
```

ğŸ—‚ **CSV Structure** (organized by POS):  

| ENG_NOUN | FRA_NOUN | BAM_NOUN | WOL_NOUN | ENG_VERB | FRA_VERB | ... |  

---

## ğŸ“ˆ Progress Feedback  

Using `tqdm` for visual updates while processing:  

```python
Translating VERB: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100
```

---

## ğŸ’¡ Customization Options

ğŸ”¹ **Modify word count per POS**  
```python
max_words = 500
```  

ğŸ”¹ **Adjust target languages**  
Edit the `target_languages` list.  

ğŸ”¹ **Optimize runtime & memory usage**  
Enable/disable checkpointing and logging.  

---

## ğŸ§¼ File Management  

All intermediate and final files (`.json`, `.csv`) are saved in **Colabâ€™s `/content/` directory**. You can download or upload them to Drive as needed.  

---

## âœ… Done!  

Once completed, youâ€™ll have a **high-quality POS-aligned multilingual dataset**, ideal for:  

âœ¨ NLP modeling  
âœ¨ Machine translation research  
âœ¨ Low-resource language studies  

---

### ğŸ”— References  

ğŸ”¹ [Meta AIâ€™s NLLB-200](https://huggingface.co/facebook/nllb-200-distilled-600M)  
ğŸ”¹ [NLTK WordNet](https://www.nltk.org/howto/wordnet.html)  
ğŸ”¹ [Universal POS Tagset](https://universaldependencies.org/u/pos/)  

---

## ğŸ‘¤ Authors  

- [Muyah Gaious](https://github.com/MUYAHGaious) â€“ Software Developer (AI & Backend Systems).  
- [Nichoh Elmic](https://github.com/Nichoh-Elmic) â€“ Web Technologies & DevOps Enthusiast.  

---

```
